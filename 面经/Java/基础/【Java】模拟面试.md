





# JUC

## 讲一讲volatile？在哪些地方用到了volatile?

**Volatile是什么**：

volatile是Java虚拟机提供的**轻量级**的**同步机制**；

**Volatile的三大特性**：

- 保证可见性
- 不保证原子性
- 禁止指令重排

## 原子性、可见性、有序性分别是什么？

**原子性**：一个操作或多个操作要么全部执行完成且执行过程不被中断，要么就不执行。

**可见性**：当多个线程同时访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。

**有序性**：程序执行的顺序按照代码的先后顺序执行。

## volatile保证可见性的原理？

**lock前缀指令角度**

缓存行（cache line）：CPU高速缓存中可以分配的最小存储单位。处理器填写缓存行时会加载整个缓存行。

观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令，lock前缀指令实际上相当于一个内存屏障。

lock指令在多核处理器下会引发下面的事件：

将当前处理器的缓存行的数据写回到系统内存，同时使其他CPU里缓存了该内存地址的数据置为无效。

为了提高处理速度，处理器一般不直接和内存通信，而是先将系统内存的数据读到内部缓存后再进行操作，但操作完成后并不知道处理器何时将缓存数据写回到内存。

但如果对加了volatile修饰的变量进行写操作，JVM就会向处理器发送一条lock前缀的指令，将这个变量在缓存行的数据写回到主存。这时只是写回到主存，但其他处理器的缓存行中的数据还是旧的，要使其他处理器缓存行的数据也是新写回到主存的数据，就需要实现缓存一致性协议。

即在一个处理器将自己缓存行的数据写回到系统内存后，其他的每个处理器就会通过嗅探在总线上传播的数据来检查自己缓存的数据是否已过期，当处理器发现自己缓存行对应的内存地址的数据被修改后，就会将自己缓存行缓存的数据设置为无效，当处理器要对这个数据进行修改操作的时候，会重新从系统内存中把数据读取到自己的缓存行，重新缓存。

总结下：volatile可见性的实现就是借助了CPU的lock指令，通过在写volatile的机器指令前加上lock前缀，使写volatile具有以下两个原则：

- 写volatile时处理器会将缓存写回到主内存。
- 一个处理器的缓存写回到内存会导致其他处理器的缓存失效。

**内存屏障角度**

内存屏障（memory barriers）：一组处理器指令，用于实现对内存操作的顺序限制。

java数据原子操作（内存间交互操作）：

read(读取)：从主存中读取数据

load(载入)：将读取到的数据写入到工作内存中

use(使用)：从工作内部中读取数据并计算

assign(赋值)：将计算好的值重新赋值到工作内存中

store(存储)：将工作内存中的数据写入到主存

write(写入)：将store过去的变量值赋值给主存中的变量
如果把一个变量从主存中拷贝到工作内存中，就要按顺序执行read和load操作，同理如果把变量从工作内存同步到主存中，就要按顺序执行store和write指令，java内存模型要求上面的两个操作必须按顺序执行，但是并不要求连续执行。

为了保证可见性：

load、use的执行顺序不被打乱 (保证使用变量前一定进行了load操作，从主存拿最新值来)

assign、wirte的执行顺序不被打乱（保证赋值后马上就是把值写到主存）。

**所以需要使用读屏障和写屏障：**一组处理器指令，用于实现对内存操作的顺序限制。

读操作时在读指令use之前插入读屏障，重新从主存加载最新值进来，让工作内存中的数据失效，强制从新从主内存加载数据。（读屏障保证在该屏障之后，对共享变量的读取，加载的是主存中最新数据 ）

写操作时在写指令assign之后插入写屏障，能让写入工作内存中的最新数据更新写入主内存，让其他线程可见。（写屏障保证在该屏障之前的，对共享变量的改动，都同步到主存当中，其他线程就可以读到最新的结果了 ）

## volatile保证有序性的原理？

**指令重排序角度**

重排序是指编译器和处理器为了优化程序性能而对指令序列进行重新排序的一种手段。（好处）

在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。重排序分3种类型。

- 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。
- 指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。
- 内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。

从Java源代码到最终实际执行的指令序列，会分别经历下面3种重排序:

![](https://cdn.jsdelivr.net/gh/xzMhehe/StaticFile_CDN/static/img202212191009973.png)

上述的1属于编译器重排序，2和3属于处理器重排序。这些重排序可能会导致多线程程序出现内存可见性问题。

对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM的处理器重排序规则会要求Java编译器在生成指令序列时，插入特定类型的内存屏障指令，通过内存屏障指令来禁止特定类型的处理器重排序。JMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。

**内存屏障角度**

写屏障会确保指令重排序时，不会将写屏障之前的代码排在写屏障之后；

读屏障会确保指令重排序时，不会将读屏障之后的代码排在读屏障之前；

HashMap

**为什么是8，而不是9不是10？**

理想情况下，在随机哈希码下，哈希表中节点的频率遵循泊松分布，而根据统计，忽略方差，列表长度为K的期望出现的次数是以上的结果，可以看到其实在为8的时候概率就已经很小了，再往后调整并没有很大意义。

```bash
The first values are:
      0:    0.60653066
      1:    0.30326533
      2:    0.07581633
      3:    0.01263606
      4:    0.00157952
      5:    0.00015795
      6:    0.00001316
      7:    0.00000094
      8:    0.00000006
      more: less than 1 in ten million
```

**为什么要转红黑树？**

回答自然很简单，因为链表是取一个数需要遍历链表，复杂度为O(N)，而红黑树为O(logN)呗，那么问题来了

为什么不直接使用红黑树，而是要先使用链表实在不行再转红黑树呢？

**因为树节点的大小是链表节点大小的两倍，所以只有在容器中包含足够的节点保证使用才用它**，但是在节点数比较小的时候，此时对于红黑树来说内存上的劣势会，超过查找等操作的优势，自然使用链表更加好，但是在节点数比较多的时候，综合考虑，红黑树比链表要好。

**为什么要在数组长度大于64之后，链表才会进化为红黑树**

在数组比较小时如果出现红黑树结构，反而会降低效率，而红黑树需要进行左旋右旋，变色，这些操作来保持平衡，同时数组长度小于64时，搜索时间相对要快些，总之是为了加快搜索速度，提高性能。

## synchronized

**是Java中的关键字，是一种同步锁。它修饰的对象有以下几种：** 

　　1. 修饰一个代码块，被修饰的代码块称为同步语句块，其作用的范围是大括号{}括起来的代码，作用的对象是调用这个代码块的对象； 
　　2. 修饰一个方法，被修饰的方法称为同步方法，其作用的范围是整个方法，作用的对象是调用这个方法的对象； 
　　3. 修改一个静态的方法，其作用的范围是整个静态方法，作用的对象是这个类的所有对象； 
　　4. 修改一个类，其作用的范围是synchronized后面括号括起来的部分，作用主的对象是这个类的所有对象。
